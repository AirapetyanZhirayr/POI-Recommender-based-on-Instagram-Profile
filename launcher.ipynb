{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instabot import InstaScrapper\n",
    "from preprocessing_data import build_csv, extract_city_country\n",
    "api_key='AIzaSyD6cpfmtzEv45PkPgTuKi6Ai0ow66Xc8Kg'\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "login\n",
    "password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = InstaScrapper(login, password, testing=True)\n",
    "scrapper.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_num = 1506\n",
    "EMBEDDING_DIM = 300\n",
    "LSTM_NUM_UNITS = 512\n",
    "\n",
    "with open('data/poi2id.json') as f:\n",
    "    poi2id = json.load(f)\n",
    "with open('data/id2poi.json') as f:\n",
    "    id2poi = json.load(f)\n",
    "\n",
    "def indexing(_context):\n",
    "    context = [poi2id.get(poi, 0) for poi in _context]\n",
    "    return context\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    max_len = max_len or max(map(len, sequences))\n",
    "    matrix = np.zeros((len(sequences), max_len), dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        matrix[i, :len(seq)] = seq\n",
    "    return matrix\n",
    "\n",
    "class LSTMLoop(nn.Module):\n",
    "    def __init__(self, poi_num, embedding_dim, lstm_num_units, embedding_matrix):\n",
    "        super().__init__()\n",
    "        self.poi_num = poi_num\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_num_units = lstm_num_units\n",
    "        self.weight = Variable(torch.FloatTensor(embedding_matrix))\n",
    "        \n",
    "        self.emb = nn.Embedding(self.poi_num, self.embedding_dim, _weight=self.weight)\n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.lstm_num_units, batch_first=True)\n",
    "        self.logits = nn.Linear(self.lstm_num_units, self.poi_num)\n",
    "        \n",
    "        self.emb.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self, context):\n",
    "        lstm_inp = self.emb(context)\n",
    "        lstm_out, _ = self.lstm(lstm_inp)\n",
    "        logits = self.logits(lstm_out)\n",
    "        return logits\n",
    "    \n",
    "def predict_word(network, seq, k=1):\n",
    "    network.train(False)\n",
    "    previous_word = Variable(torch.LongTensor(as_matrix([seq])))\n",
    "    next_word_logits = network.forward(previous_word)[0, -1]\n",
    "    next_word_probs = F.softmax(next_word_logits, -1).detach().numpy()\n",
    "    next_word_ix = np.argsort(next_word_probs)[::-1]\n",
    "    if k == 'all':\n",
    "        return next_word_ix\n",
    "    return next_word_ix[:k]\n",
    "    \n",
    "EMBEDDING_MATRIX = np.loadtxt('data/emb_mat.txt')\n",
    "network = LSTMLoop(poi_num, EMBEDDING_DIM, LSTM_NUM_UNITS, EMBEDDING_MATRIX)\n",
    "network.load_state_dict(torch.load('data/lstm_weight.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user(username):\n",
    "    '''\n",
    "    Predicting locations straight from user\n",
    "    instagram page\n",
    "    '''\n",
    "    user_data = scrapper.collect_user_data(username)  \n",
    "    if user_data:\n",
    "        user_df = build_csv(user_data, testing=True)\n",
    "        user_data = []\n",
    "        for idx, row in user_df.iterrows():\n",
    "            user_data.append((row['location'], row['timestamp']))\n",
    "        user_data = list(map(lambda y: y[0], sorted(user_data, key=lambda x: x[1])))\n",
    "        \n",
    "        \n",
    "        user_data_processed = []\n",
    "        for loc in (user_data):\n",
    "            url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={loc}&key={api_key}\"\n",
    "            request = requests.get(url).json()\n",
    "            if request['status'] == 'OK':\n",
    "                result = request['results']\n",
    "                if result:\n",
    "                    result = result[0]\n",
    "                    _loc = extract_city_country(result['address_components'])\n",
    "                    city = _loc['city']\n",
    "                    country = _loc['country']\n",
    "\n",
    "\n",
    "                    user_data_processed.append(city + ', ' + country)\n",
    "                    \n",
    "        user_data_processed = indexing(user_data_processed)\n",
    "        predict_labels = predict_word(network, user_data_processed, 5)\n",
    "        return [id2poi[label] for label in predict_labels]\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Moskva, Russia',\n",
       " 'Moscow, Russia',\n",
       " 'Campania, Italy',\n",
       " 'Missouri, United States',\n",
       " 'Bali, Indonesia']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_user('milissakir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
